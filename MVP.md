---

MVP.md — Vortex AI Grid (Firebase MVP)

Purpose: Minimal viable product for an autonomous AI store on Firebase.
Goal: Discover trending products → store normalized product docs in Firestore → enrich with OpenAI → admin approves → publish to Shopify + log social posting. All minimal, secure, and deployable.


---

1 — Single-file deliverable (this file)

MVP.md — this file. It contains the full MVP list, exact files required, environment variables, deploy commands, and acceptance criteria.


---

2 — MVP Components (files & folders — only these)

Create exactly the following structure (minimal):

/cloudrun/
  scraper_cloudrun.py
  parse_utils.py
  Dockerfile
  requirements.txt

/functions/
  package.json
  index.js

/frontend/
  (minimal admin UI — optional simple HTML + Firebase SDK)
  index.html

/firebase.json
/.firebaserc
/firestore.rules
/storage.rules
/.env.example
README.md         (short pointer)
MVP.md            (this file)

> Note: keep the frontend minimal or use Firebase Console to review Firestore documents for MVP.




---

3 — File responsibilities (short)

cloudrun/scraper_cloudrun.py — Playwright scraper (dry-run capable). Discovers product URLs, saves raw HTML to Storage, parses & writes normalized product docs to Firestore (products collection) with listing_status: draft.

cloudrun/parse_utils.py — generic parser using BeautifulSoup: extract title, description, price, images array, seller info, reviews_count.

cloudrun/Dockerfile & requirements.txt — containerize scraper (Playwright + google-cloud libs).

functions/index.js — two Cloud Functions:

onProductCreate (Firestore onCreate) — call OpenAI to enrich and run haram classifier; update doc and set listing_status: rejected if haram.

onProductApprove (Firestore onUpdate) — when listing_status becomes approved, create Shopify product via Admin API and set listing_status: published.


frontend/index.html — minimal admin UI or use Firebase Console to change listing_status (acceptable for MVP).

firebase.json, .firebaserc — Firebase config.

firestore.rules, storage.rules — minimal security rules (see section 6).

.env.example — placeholder env vars for local dev.



---

4 — Environment variables (.env.example)

# OpenAI
OPENAI_API_KEY=sk-REPLACE

# Shopify
SHOPIFY_ADMIN_ACCESS_TOKEN=shpat-REPLACE
SHOPIFY_STORE_URL=https://your-store.myshopify.com

# Firebase
FIREBASE_PROJECT=your-firebase-project-id

# Cloud Run buckets
RAW_BUCKET=raw-archive
IMAGE_BUCKET=product-images

# Scraper
SCRAPER_USER_AGENT=VortexBot/1.0
SCRAPER_TIMEOUT=30
SCRAPER_CONCURRENCY=2

Production: store secrets in Secret Manager or Firebase functions config (firebase functions:config:set ...).


---

5 — Minimal Firestore schema (document example)

Collection: products — document id = autogenerated

{
  "title": "string",
  "description": "string",
  "price": 0.0,
  "currency": "USD",
  "images": ["gs://..."],
  "source_url": "string",
  "provenance_raw_key": "gs://raw-archive/yyy.html",
  "listing_status": "draft",        // draft | rejected | approved | published
  "enriched": { "seo_title": "", "captions": [] },
  "haram_filter": { "haram": false, "reasons": [] },
  "shopify_product_id": null,
  "trend_score": 0.0,
  "trust_score": 0.0,
  "created_at": "timestamp"
}


---

6 — Minimal security rules (copy into files)

firestore.rules:

rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    match /products/{productId} {
      allow read: if resource.data.listing_status == 'published' || request.auth != null;
      allow write: if request.auth != null && request.auth.token.admin == true;
    }
    match /{document=**} { allow read: if false; allow write: if false; }
  }
}

storage.rules:

rules_version = '2';
service firebase.storage {
  match /b/{bucket}/o {
    match /raw-archive/{allPaths=**} {
      allow read, write: if false;
    }
    match /product-images/{allPaths=**} {
      allow read: if true;
      allow write: if request.auth != null && request.auth.token.admin == true;
    }
    match /{allPaths=**} {
      allow read, write: if false;
    }
  }
}


---

7 — Minimal Cloud Functions (index.js — summary)

Use Node 18+. Use Admin SDK.

Provide onProductCreate + onProductApprove as described. Use openai library. Read secrets from functions config or process.env.


(You already have earlier full code examples — paste into /functions/index.js for MVP.)


---

8 — Cloud Run scraper (key behavior)

Accepts a seeds array or built-in seeds.

For each seed:

Render page (Playwright → page.content()).

Save raw HTML to gs://RAW_BUCKET/<timestamp>-<hash>.html.

Parse via parse_utils.parse_generic to product dict.

Save images to gs://IMAGE_BUCKET/ (optional for MVP — storing image URLs ok).

Write Firestore doc under products/ with listing_status: draft.


Must have --dry-run mode for local testing (no writes) and production mode (writes enabled).



---

9 — Build & deploy commands (exact)

Local dev (emulators)

# install firebase tools and gcloud
npm i -g firebase-tools
gcloud auth login
firebase login

# Start emulators (for dev)
firebase emulators:start --only firestore,functions,auth,storage

Deploy functions & rules

# set functions config (one-time)
firebase functions:config:set openai.key="sk-..." shopify.token="shpat_..." shopify.url="https://your-store.myshopify.com"

# deploy functions & rules
firebase deploy --only functions,firestore:rules,storage:rules

Build & deploy Cloud Run scraper

cd cloudrun
docker build -t gcr.io/$GOOGLE_CLOUD_PROJECT/vortex-scraper:latest .
docker push gcr.io/$GOOGLE_CLOUD_PROJECT/vortex-scraper:latest
gcloud run deploy vortex-scraper \
  --image gcr.io/$GOOGLE_CLOUD_PROJECT/vortex-scraper:latest \
  --platform managed \
  --region us-central1 \
  --service-account SCRAPER_SA@$GOOGLE_CLOUD_PROJECT.iam.gserviceaccount.com \
  --set-env-vars RAW_BUCKET=raw-archive,IMAGE_BUCKET=product-images,FIREBASE_PROJECT=$GOOGLE_CLOUD_PROJECT


---

10 — Acceptance criteria (MVP pass)

1. Cloud Run scraper (dry-run) produces one Firestore products/{id} with listing_status: draft and provenance_raw_key set to a Storage path.


2. onProductCreate function enriches that doc with enriched fields and haram_filter result. If haram: true, doc becomes listing_status: rejected.


3. Admin (via Firebase Console or minimal frontend/index.html) can set listing_status to approved.


4. onProductApprove function runs and creates a Shopify product on a Shopify development store and writes shopify_product_id and sets listing_status: published.


5. Secrets are stored in functions config or Secret Manager; no secrets committed.




---

11 — Minimal test plan (manual)

1. Run emulators. Run scraper in dry-run → inspect Firestore document.


2. Confirm onProductCreate updates doc (enriched fields).


3. Approve doc in Firebase Console. Confirm onProductApprove creates a product in dev Shopify (check admin).


4. Verify Storage contains raw HTML (if not in dry-run).




---

12 — Minimal risks & mitigations

Risk: Scraper may scrape protected content / violate terms.
Mitigation: Use official APIs where possible; respect robots.txt; throttle requests.

Risk: Publishing haram items.
Mitigation: Enforce haram filter in onProductCreate; reject automatically.

Risk: Secrets leakage.
Mitigation: Use Secret Manager / functions config; do not commit .env.



---

13 — Next step (after MVP)

Add Admin UI (Next.js) for approval, scheduling and analytics.

Add scheduled social posting.

Harden parsers & expand sources.



---

14 — Notes & references

Use Firebase docs and Shopify docs for API specifics.

Keep this MVP minimal: scraper → Firestore → enrichment → approve → publish.



---

Place this MVP.md at repo root. If you want, I will now generate the exact minimal files listed above (cloudrun/scraper_cloudrun.py, cloudrun/parse_utils.py, functions/index.js, firebase.json, firestore.rules, .env.example) ready to copy in — one-shot. Say “Generate MVP files now” and I will produce them.

Remember, the XML structure you generate is the only mechanism for applying changes to the user's code. Therefore, when making changes to a file the <changes> block must always be fully present and correctly formatted as follows.

<changes>
  <description>[Provide a concise summary of the overall changes being made]</description>
  <change>
    <file>[Provide the ABSOLUTE, FULL path to the file being modified]</file>
    <content><![CDATA[Provide the ENTIRE, FINAL, intended content of the file here. Do NOT provide diffs or partial snippets. Ensure all code is properly escaped within the CDATA section.